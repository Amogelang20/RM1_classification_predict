{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Predict - Climate Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# background and problem statement "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What data do we have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# description of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "# !pip install comet_ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the API key (saved as environment variable)\n",
    "# experiment = Experiment(api_key=\"upOwchWrd7H1e6VEnWKW7PSvz\", project_name=\"classification-predict\", workspace=\"team-rm1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import SnowballStemmer\n",
    "from nltk import word_tokenize\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('https://raw.githubusercontent.com/Amogelang20/RM1_classification_predict/dev/test.csv')\n",
    "df_train = pd.read_csv('https://raw.githubusercontent.com/Amogelang20/RM1_classification_predict/dev/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573736</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466954</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                            message\n",
       "tweetid                                                              \n",
       "625221           1  PolySciMajor EPA chief doesn't think carbon di...\n",
       "126103           1  It's not like we lack evidence of anthropogeni...\n",
       "698562           2  RT @RawStory: Researchers say we have three ye...\n",
       "573736           1  #TodayinMaker# WIRED : 2016 was a pivotal year...\n",
       "466954           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.set_index('tweetid',inplace = True)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>169760</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35326</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224985</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476263</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\r\\nPu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872928</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   message\n",
       "tweetid                                                   \n",
       "169760   Europe will now be looking to China to make su...\n",
       "35326    Combine this with the polling of staffers re c...\n",
       "224985   The scary, unimpeachable evidence that climate...\n",
       "476263   @Karoli @morgfair @OsborneInk @dailykos \\r\\nPu...\n",
       "872928   RT @FakeWillMoore: 'Female orgasms cause globa..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.set_index('tweetid',inplace = True)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploratory data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at the type of data that is present. \n",
    "# look at the types and number of columns present. \n",
    "# look at the y variable, the number of classes it has. \n",
    "# check for imbalance of data in the different classes of y variable. \n",
    "# check for missing values.\n",
    "# visualise the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CLEANING ####\n",
    "# handle some of the unnecessary punctuation \n",
    "# upper/lower case\n",
    "# change the slang words into something more meaningful to machine learning\n",
    "# handle missing data and empty strings\n",
    "# ect.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief doesn't think carbon di...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>1</td>\n",
       "      <td>it's not like we lack evidence of anthropogeni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>698562</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @rawstory: researchers say we have three ye...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573736</th>\n",
       "      <td>1</td>\n",
       "      <td>#todayinmaker# wired : 2016 was a pivotal year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466954</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @soynoviodetodas: it's 2016, and a racist, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22001</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @ezlusztig: they took down the material on ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17856</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @washingtonpost: how climate change could b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384248</th>\n",
       "      <td>0</td>\n",
       "      <td>notiven: rt: nytimesworld :what does trump act...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819732</th>\n",
       "      <td>-1</td>\n",
       "      <td>rt @sara8smiles: hey liberals the climate chan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>806319</th>\n",
       "      <td>0</td>\n",
       "      <td>rt @chet_cannon: .@kurteichenwald's 'climate c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                            message\n",
       "tweetid                                                              \n",
       "625221           1  polyscimajor epa chief doesn't think carbon di...\n",
       "126103           1  it's not like we lack evidence of anthropogeni...\n",
       "698562           2  rt @rawstory: researchers say we have three ye...\n",
       "573736           1  #todayinmaker# wired : 2016 was a pivotal year...\n",
       "466954           1  rt @soynoviodetodas: it's 2016, and a racist, ...\n",
       "...            ...                                                ...\n",
       "22001            1  rt @ezlusztig: they took down the material on ...\n",
       "17856            2  rt @washingtonpost: how climate change could b...\n",
       "384248           0  notiven: rt: nytimesworld :what does trump act...\n",
       "819732          -1  rt @sara8smiles: hey liberals the climate chan...\n",
       "806319           0  rt @chet_cannon: .@kurteichenwald's 'climate c...\n",
       "\n",
       "[15819 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop missing texts\n",
    "df_train.dropna(inplace = True)\n",
    "\n",
    "#dropping empty tweets\n",
    "blanks = []  # start with an empty list\n",
    "for i,lb,tweet in df_train.itertuples():  # iterate over the DataFrame\n",
    "    if type(tweet)==str:            # avoid NaN values\n",
    "        if tweet.isspace():         # test 'tweet' for whitespace\n",
    "            blanks.append(i)     # add matching index numbers to the list\n",
    "df_train.drop(blanks, inplace=True)\n",
    "\n",
    "#lower case all words to remove noise from Capital words. Capital words may be seen as different from lower case words\n",
    "df_train['message'] = df_train['message'].str.lower()\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    #substring\n",
    "    \n",
    "    #drop missing texts\n",
    "    df.dropna(inplace = True)\n",
    "\n",
    "    #dropping empty tweets\n",
    "    blanks = []  # start with an empty list\n",
    "    for i,lb,tweet in df.itertuples():  # iterate over the DataFrame\n",
    "        if type(tweet)==str:            # avoid NaN values\n",
    "            if tweet.isspace():         # test 'tweet' for whitespace\n",
    "                blanks.append(i)     # add matching index numbers to the list\n",
    "    df.drop(blanks, inplace=True)\n",
    "\n",
    "    #lower case all words to remove noise from Capital words. Capital words may be seen as different from lower case words\n",
    "    df['message'] = df['message'].str.lower()\n",
    "    \n",
    "    df['message'] = df['message'].replace(r'&amp;', 'and', regex=True) #replace & with and\n",
    "    df['message'] = df['message'].replace(r'https\\S+','', regex=True).replace(r'www\\S+', '', regex=True) #removing urls\n",
    "    df['message'] = df['message'].str.replace('rt','retweet') #replace 'rt' with retweet\n",
    "    df['message'] = df['message'].str.replace('[^\\w\\s]','') #removing punctuations\n",
    "\n",
    "    # remove duplicate tweets\n",
    "    df_train.drop_duplicates(subset=['message'],keep = 'first',inplace = True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create some features from the given tweets,e.g length of tweet. Visualise these created features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into response and predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### clean_message = the cleaned text data ####\n",
    "y = df_train['sentiment']\n",
    "X = df_train['clean_message']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines to vectorize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stem, tokenize and remove stopwords (all done within vectorization)\n",
    "# Build a pipeline that vectorizes the text and creates classifiers for the different models \n",
    "# (logistic reg, SVM, Naive Bayes, Random Forest, Neural Nets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write class that has object that tokenizes text data AND stems the tokens\n",
    "class StemAndTokenize:\n",
    "    def __init__(self):\n",
    "        self.ss = SnowballStemmer('english')\n",
    "    def __call__(self, doc):\n",
    "        return [self.ss.stem(t) for t in word_tokenize(doc)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Logistic Regression:\n",
    "lr = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('lr', LogisticRegression())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Naïve Bayes:\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('nb', MultinomialNB())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for SVM:\n",
    "Lsvm = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('Lsvm', LinearSVC())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Random Forest:\n",
    "rf = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('rf', RandomForestClassifier())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN (K Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for KNN:\n",
    "knn = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('knn', KNeighborsClassifier())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Neural Networks:\n",
    "nn = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('nn', MLPClassifier())\n",
    "              ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimize models by tuning parameters (GridSearch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Logistic Regression model\n",
    "lr.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Naïve Bayes model\n",
    "nb.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM (Support Vector Machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the SVM model\n",
    "Lsvm.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Random Forest model\n",
    "rf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNN (K Nearest Neighbors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the KNN model\n",
    "knn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting the Neural Networks model\n",
    "nn.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "# classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predicts \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pickle model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save parameters in variables to be logged to comet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
