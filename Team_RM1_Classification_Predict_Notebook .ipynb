{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Predict - Climate Change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![eco-friendly.jpg](eco-friendly.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "1. [Problem identification](#the_problem)  \n",
    "\n",
    "\n",
    "2. [What data do we have?](#the_data)  \n",
    "    2.1. [Install necessary packages](#install)  \n",
    "    2.2. [Start experiment](#exps)  \n",
    "    2.3. [Import the libraries](#imp_lib)  \n",
    "    2.4. [Import the dataset](#imp_data)  \n",
    "    \n",
    "    \n",
    "3. [Exploratory data analysis](#the_analysis)   \n",
    "    \n",
    "    \n",
    "4. [Preprocessing](#the_prep)  \n",
    "    4.1. [Data cleaning](#clean)  \n",
    "    4.2. [Split data into response and predictors](#split1)  \n",
    "    4.3. [Split data into training and validation sets](#split2)    \n",
    "    \n",
    "    \n",
    "5. [Build pipelines for feature extraction](#vect)  \n",
    "    5.1. [Vectorize](#v)  \n",
    "    5.2. [Stem](#s)  \n",
    "    5.3. [Tokenization](#t)  \n",
    "    5.4. [Remove stopwords](#rs)  \n",
    "    5.5. [Hyperparameter optimization](#optimize)\n",
    "\n",
    "\n",
    "6. [Train models](#train)  \n",
    "\n",
    "\n",
    "7. [Make predictions](#pred)  \n",
    "\n",
    "\n",
    "8. [Evaluate model accuracy](#the_eval)  \n",
    "    8.1. [Confusion matrices](#mat)  \n",
    "    8.2. [Classification report](#report)  \n",
    "\n",
    "\n",
    "9. [Saving important data](#sav)  \n",
    "    9.1. [Save the model](#mod)  \n",
    "    9.2. [Save the graphs](#graph)\n",
    "\n",
    "\n",
    "10. [Log parameters](#log)  \n",
    "\n",
    "\n",
    "11. [Conclusion](#the_conclusion)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Problem identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In a [research article](https://www.barrons.com/articles/two-thirds-of-north-americans-prefer-eco-friendly-brands-study-finds-51578661728) conducted, 19,000 customers from 28 countries where given a poll to find out how individual shopping decisions are changing. Nearly 70% of consumers in the U.S. and Canada find that it is important for a company or brand to be sustainable or eco-friendly. More than a third (40%) of the respondents globally said that they are purpose-driven consumers, who select brands based on how well they align with their personal beliefs.\n",
    "\n",
    "Many companies are built around lessening their environmental impact or carbon footprint. They offer products and services that are environmentally friendly and sustainable, in line with their values and ideals. They would like to determine how people perceive climate change and whether or not they believe it is a real threat. This would add to their market research efforts in gauging how their product/service may be received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "#### Problem statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Build a machine learning model that is able to classify whether or not an individual believes in man-made climate change based on historical tweet to increase insights about customers and inform future marketing strategies.\n",
    "\n",
    "You can find the project overview [here](https://www.kaggle.com/c/climate-change-belief-analysis/overview)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## What data do we have?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset that will be used in this classification project aggregates tweets pertaining to climate change, collected between Apr 27, 2015 and Feb 21, 2018. In total, 15819 tweets are used in the dataset. The data consists of 3 columns; tweetid, sentiment and message. A description of each column in the data is given below"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Variable definitions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| **Variable** | **Description**   |\n",
    "|:------------:|:------------------|\n",
    "|**tweetid**   | Twitter unique ID |\n",
    "|**message**   | Tweet body        |\n",
    "|**sentiment** | Sentiment of tweet|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    " Each tweet is labelled as one of the following classes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "| **Class** | **Tag** | **Description** |\n",
    "|:---------:|:----------------:|:----------------|\n",
    "|   **2**   | **News** |The tweet links to factual news about climate change |\n",
    "|   **1**   | **Pro** |The tweet supports the belief of man-made climate change |\n",
    "|   **0**   | **Neutral** |The tweet neither supports nor refutes the belief of man-made climate change |\n",
    "|  **-1**   | **Anti** |The tweet does not believe in man-made climate change |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "!pip install comet_ml\n",
    "!pip install seaborn\n",
    "!pip install wordcloud\n",
    "!pip install emoji\n",
    "!pip install pyspellchecker\n",
    "!pip install ftfy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Start experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# from comet_ml import Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Setting the API key (saved as environment variable)\n",
    "# experiment = Experiment(api_key=\"upOwchWrd7H1e6VEnWKW7PSvz\", project_name=\"classification-predict\", workspace=\"team-rm1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 1. Importing packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook requires some packages that may not be installed on your local machine. Below we provide a list of packages to be installed (if they are not yet installed) and the code to install them.  \n",
    "\n",
    "Run the following commands within Git bash (Windows), terminal (Mac/Linux) or inside your Anaconda Prompt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Comet_ml - `pip install comet_ml==3.1.9`  \n",
    "- Seaborn - `pip install seaborn==0.9.0`  \n",
    "- Wordcloud - `pip install wordcloud==1.7.0`  \n",
    "- Emoji - `pip install emoji==0.5.4`  \n",
    "- Pyspellchecker - `pip install pyspellchecker==0.5.4`  \n",
    "- Ftfy - `pip install ftfy==5.7`  \n",
    "- PyLDAvis - `pip install pyldavis==2.1.2`  \n",
    "- Gensim - `pip install gensim==`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\statsmodels\\tools\\_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
      "  import pandas.util.testing as tm\n"
     ]
    }
   ],
   "source": [
    "# Packages for data analysis\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Packages for visualisations\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# Packages for preprocessing\n",
    "import re\n",
    "from nltk import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.probability import FreqDist\n",
    "import emoji\n",
    "from ftfy import fix_text\n",
    "from spellchecker import SpellChecker \n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Packages for training models\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# Packages for hyperparameter optimisation\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Packages for evaluating model accuracy\n",
    "from sklearn.metrics import f1_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Packages for saving models\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## 2. Importing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('https://raw.githubusercontent.com/Amogelang20/RM1_classification_predict/dev/test.csv')\n",
    "df_train = pd.read_csv('https://raw.githubusercontent.com/Amogelang20/RM1_classification_predict/dev/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import training dataset\n",
    "df_train.set_index('tweetid',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Import testing dataset\n",
    "df_test.set_index('tweetid',inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_eda=df_train.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Data cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `message` column is currently in its raw form and needs to be cleaned for the model to be able to better process, analyze and provide predictions for sentiments. Before we start cleaning, we'll extract some extra features that could possibly improve our model's predicting accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Extra feature extraction**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first feature we will extract is the sentiment of a tweet. We determine the sentiment of a tweet by using python's VADER library. This feature could be useful since we would expect tweets classified as `Anti` to have a more negative tone than tweets classified as `Pro`. We'll start by writing a function that takes a text string as input and determines its sentiment, i.e. negative, positive or neutral. Since these tweets do not have a wide range when it comes to sentiment scores (rarely more than 0.4) we decided to classify all tweets with scores of less than -0.05 as negative, scores between -0.05 and 0.05 where classified as neutral and a score of more than 0.05 indicated a positive tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Function to extract sentiment\n",
    "def sentiment_score(text):\n",
    "    \"\"\" A function that determines the sentiment of a text string.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: Text string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sentiment:  String indicating the sentiment of the input string.\n",
    "    \"\"\"\n",
    "    \n",
    "    sid = SentimentIntensityAnalyzer()\n",
    "    s = sid.polarity_scores(text)['compound']\n",
    "    if s<-0.05:\n",
    "        sentiment='negative'\n",
    "    elif s>0.05:\n",
    "        sentiment='positive'\n",
    "    else:\n",
    "        sentiment='neutral'\n",
    "    \n",
    "    return sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Twitter handles could be a second useful feature. Sentiment will help us a lot with classifying classes like `Anti`, `Neutral` and `Pro`, but we would find it more difficult to classify `News` using these sentiments. Twitter handles could help the model distinguish between the `News` class and the other classes. We assume that tweets classified as `News` would've probably been extracted from news accounts and therefore have news related handles.  \n",
    "\n",
    "We now extract all **unique** Twitter handles found in tweets within the `News` class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Extract all unique news related handles into a list\n",
    "df_temp = df_train.copy()\n",
    "df_temp.sort_index(inplace=True)\n",
    "n_temp = [re.findall(r'@[\\w]+',df_temp['message'].iloc[i]) for i,x in enumerate(df_temp['sentiment']) if x==2]\n",
    "news = [x for x in n_temp if x!=[]]\n",
    "news = sorted(list(set(itertools.chain.from_iterable(news))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 entries: ['@02Cents0', '@100isNow', '@1306Chomley', '@1o5CleanEnergy', '@233liveOnline'] \n",
      "Last 5 entries: ['@yceek', '@yearsofliving', '@yicaichina', '@zsstevens', '@Ã']\n"
     ]
    }
   ],
   "source": [
    "print(f'First 5 entries: {news[:5]} \\nLast 5 entries: {news[-5:]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Looking at the first and last 5 entries inside our list we see our hunch was correct. We can see news channels like `@233liveOnline` and organizations like `@100isNow` (better known as \"The Solutions Project\") that has made it clear that their goal is to radically transform how people understand climate change and the role we all can play to solve it. There are also handles from influential people like `@zsstevens` (Stewart Stevenson), former Scottish Minister for Environment and Climate Change from, and is currently still part o fthe Environment, Climate Change and Land Reform Committee for the Scottish Parliament.  \n",
    "\n",
    "We have now created our features and move on to cleaning the text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Hashtags**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "`#Hashtags` are used to make a statement about something, or to start a conversation around a specific topic or trend. In twitter data a lot of hashtags are generally used and may contain viable information that indicate a certain sentiment towards a specific topic. However, hashtags are a compressed set of words or sentences and since they are recorded as 1 word it may be hard for the model to decipher them. For this reason a dictionary,`hashtags`, has been created. This dictionary contains all the possible hashtags about climate change along with their corresponding decompressed words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We start by extracting all unique hashtags from the training dataset and export them into two seperate .PKL files. One will be used for the keys in the dictionary and the other will be used for values (separated words). _These files are then modified further outside the jupyter notebook._ \n",
    "\n",
    "*Below we show the code that was used to extract and export all unique hashtags. This is merely for illustration of the process taken.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "***\n",
    "\n",
    "`hashtags = df_train['message'].apply(lambda x: re.findall(r'[#]\\\\w+',x))`  \n",
    "\n",
    "**Extracting all unique hashtags**  \n",
    "`hashtags = list(set([item for sublist in hashtags for item in sublist])) `  \n",
    "\n",
    "**Exporting twice. One is used for the keys in the dictionary and the other is used for values(separated words).**  \n",
    "`with open('hash_file', 'wb') as fp:`  \n",
    "`    pickle.dump(hashtags, fp)`  \n",
    "`with open('hash_file_clean', 'wb') as fp:`  \n",
    "`    pickle.dump(itemlist, fp)`  \n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "After modifying those files we will load them back into the notebook to help with preprocessing the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Read in created hashtag text file and create a hashtags dictionary\n",
    "\n",
    "# Keys\n",
    "hash_file = [line.rstrip('\\n') for line in open('hash_file.txt')]\n",
    "hash_file = [i.center(len(i)+2) for i in hash_file]\n",
    "\n",
    "# Values\n",
    "hash_file_clean = [line.rstrip('\\n') for line in open('hash_file_clean.txt')] \n",
    "hash_file_clean = [i.center(len(i)+2) for i in hash_file_clean]\n",
    "\n",
    "hashtags = {hash_file[i]: hash_file_clean[i] for i in range(len(hash_file))} \n",
    "hashtags.update({'todayinmaker ':'today in maker'})#this is added to differentiate it from ' todayinmaker ' because this 1 occurs at start of tweet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next we write a function to expand hashtags inside the text data into seperate words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Substitute hastags with separated words\n",
    "def expand_hashtags(df,column_name):\n",
    "    \"\"\" A funtion that expands the hashtag words into separate words.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df:          Dataframe containing the text column to be transformed.\n",
    "        column_name: Name of the column containing the text data.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df:  Dataframe containg the updated text column\n",
    "        \n",
    "        Example\n",
    "        -------\n",
    "        #iamgreat returns 'i am great'\n",
    "    \"\"\"\n",
    "    \n",
    "    df[column_name] = df[column_name].str.lower()\n",
    "    df[column_name] = df[column_name].apply(lambda x: re.sub(r\"[#]\",'',x))\n",
    "    for word in hashtags.keys():\n",
    "            df[column_name] = df[column_name].apply(lambda x: re.sub(word,hashtags[word]+' ',x))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_train = expand_hashtags(df_train,'message')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Contractions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `message` column contains some contracted words such as *can't* and *don't*. As part of the cleaning process these words will be replaced with their expanded words that do not contain any omission. We do this because we will need to tokenize the text later on. We assume that a model would have an easier time using tokens like `can` and `not` than `can` and `'t`. To help with this transformation, a dictionary `contractions` is created, that contain possible contractions and their corresponding full words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Dictionary of contracted words\n",
    "contractions = {\n",
    "\"aren't\" : \"are not\",\n",
    "\"can't\" : \"cannot\",\n",
    "\"couldn't\" : \"could not\",\n",
    "\"didn't\" : \"did not\",\n",
    "\"doesn't\" : \"does not\",\n",
    "\"don't\" : \"do not\",\n",
    "\"hadn't\" : \"had not\",\n",
    "\"hasn't\" : \"has not\",\n",
    "\"haven't\" : \"have not\",\n",
    "\"he'd\" : \"he would\",\n",
    "\"he'll\" : \"he will\",\n",
    "\"he's\" : \"he is\",\n",
    "\"i'd\" : \"I would\",\n",
    "\"i'd\" : \"I had\",\n",
    "\"i'll\" : \"I will\",\n",
    "\"i'm\" : \"I am\",\n",
    "\"isn't\" : \"is not\",\n",
    "\"it's\" : \"it is\",\n",
    "\"it'll\":\"it will\",\n",
    "\"i've\" : \"I have\",\n",
    "\"let's\" : \"let us\",\n",
    "\"mightn't\" : \"might not\",\n",
    "\"mustn't\" : \"must not\",\n",
    "\"shan't\" : \"shall not\",\n",
    "\"she'd\" : \"she would\",\n",
    "\"she'll\" : \"she will\",\n",
    "\"she's\" : \"she is\",\n",
    "\"shouldn't\" : \"should not\",\n",
    "\"that's\" : \"that is\",\n",
    "\"there's\" : \"there is\",\n",
    "\"they'd\" : \"they would\",\n",
    "\"they'll\" : \"they will\",\n",
    "\"they're\" : \"they are\",\n",
    "\"they've\" : \"they have\",\n",
    "\"wasn't\": \"was not\",\n",
    "\"we'd\" : \"we would\",\n",
    "\"we're\" : \"we are\",\n",
    "\"weren't\" : \"were not\",\n",
    "\"we'll\":\"we will\",\n",
    "\"we've\" : \"we have\",\n",
    "\"what'll\" : \"what will\",\n",
    "\"what're\" : \"what are\",\n",
    "\"what's\" : \"what is\",\n",
    "\"what've\" : \"what have\",\n",
    "\"where's\" : \"where is\",\n",
    "\"who'd\" : \"who would\",\n",
    "\"who'll\" : \"who will\",\n",
    "\"who's\" : \"who is\",\n",
    "\"who've\" : \"who have\",\n",
    "\"won't\" : \"will not\",\n",
    "\"wouldn't\" : \"would not\",\n",
    "\"you'd\" : \"you would\",\n",
    "\"you'll\" : \"you will\",\n",
    "\"you're\" : \"you are\",\n",
    "\"you've\" : \"you have\",\n",
    "\"'re\": \" are\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's replace the contracted words by their expanded alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replace contracted words with full word\n",
    "df_train['message'] = [' '.join([contractions[w.lower()] if w.lower() in contractions.keys() else w for w in raw.split()]) for raw in df_train['message']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Lowercase**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To help our model, we will be converting all text to lowercase. We work with lower cased data to remove the noise from capitalised words. This is due to the computer seeing uppercased words as different from lower cased words. If this transformation is not applied we run the risk of the model possibly classifying cases like `Snowball` and `snowball` differently. By transforming we help the model understand that those two words are in fact the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Lower case all words to remove noise from Capital words. Capital words may be seen as different from lower case words\n",
    "df_train['message'] = df_train['message'].str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Encoding**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tweet data can also include bad unicode. For example, where a person wants so say `José Florés` or use a `(—)`, it ends up being `JosÃ© Florés` or `â€”` instead. These issues can make it hard for the model to process the data. There is a package in python that takes care of these issues for us. The ftfy(fixed this for you) package takes all the bad unicode and outputs the good unicode. So let's let the package fix these problems for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_train['message'] = df_train['message'].apply(lambda x: fix_text(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**URLs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We will also not be using any urls. Since urls tend to be unique and random for any class, they do not really add explanatory power and will therefore be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Removing urls\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r'https\\S+','url',x))\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r'www\\S+', 'url',x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Emojis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `message` column may also contain emojis, ex. 👨🏽‍💻. As we can see, alone they're just symbols and don't have a word association to them. This makes them hard to interpret and also makes them useless to our model. But emojis could potentially be useful in the modeling process. So instead of removing them, we'll be replacing them with the word that describes them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replace emojis with their word meaning\n",
    "df_train['message'] = df_train['message'].apply(lambda x: emoji.demojize(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Shortened words/Slang**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "With tweets data a lot of shortened words like *abt* are used instead of the full words *about*. This can make it difficult for the model to process these words. We will replace the shortened words with their corresponding full word. To help with this transformation, a dictionary of possible shortened words and their corresponding full words is given below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replace shortened words with full words\n",
    "short = {' BD ': ' Big Deal ',\n",
    " ' abt ':' about ',\n",
    " ' ab ': ' about ',\n",
    " ' fav ': ' favourite ',\n",
    " ' fab ': ' fabulous ',\n",
    " ' smh ': ' shaking my head ',\n",
    " ' u ': ' you ',\n",
    " ' c ': ' see ',\n",
    " ' anon ': ' anonymous ',\n",
    " ' ac ': ' aircon ',\n",
    " ' a/c ': ' aircon ',\n",
    " ' yo ':' year old ',\n",
    " ' n ':' and ',\n",
    " ' nd ':' and ',\n",
    " ' 2 ': ' to ',\n",
    " ' w ': ' with ',\n",
    " ' w/o ': ' without ',\n",
    " ' r ': ' are ',\n",
    " ' rip ':' rest in peace ',\n",
    " ' 4 ' : ' for ',\n",
    "' BF ': ' Boyfriend ',\n",
    "' BRB ': ' Be Right Back ',\n",
    "' BTW ': ' By The Way ',\n",
    "' GF ': ' Girlfriend ',\n",
    "' HBD ': ' Happy Birthday ',\n",
    "' JK ': ' Just Kidding ',\n",
    "' K ':' Okay ',\n",
    "' LMK ': ' Let Me Know ',\n",
    "' LOL ': ' Laugh Out Loud ',\n",
    "' HA ':' laugh ',\n",
    "' MYOB ': ' Mind Your Own Business ',\n",
    "' NBD ': ' No Big Deal ',\n",
    "' NVM ': ' Nevermind ',\n",
    "' Obv ':' Obviously ',\n",
    "' Obvi ':' Obviously ',\n",
    "' OMG ': ' Oh My God ',\n",
    "' Pls ': ' Please ',\n",
    "' Plz ': ' Please ',\n",
    "' Q ': ' Question ', \n",
    "' QQ ': ' Quick Question ',\n",
    "' RLY ': ' Really ',\n",
    "' SRLSY ': ' Seriously ',\n",
    "' TMI ': ' Too Much Information ',\n",
    "' TY ': ' Thank You, ',\n",
    "' TYVM ': ' Thank You Very Much ',\n",
    "' YW ': ' You are Welcome ',\n",
    "' FOMO ': ' Fear Of Missing Out ',\n",
    "' FTFY ': ' Fixed This For You ',\n",
    "' FTW ': ' For The Win ',\n",
    "' FYA ': ' For Your Amusement ',\n",
    "' FYE ': ' For Your Entertainment ',\n",
    "' GTI ': ' Going Through It ',\n",
    "' HTH ': ' Here to Help ',\n",
    "' IRL ': ' In Real Life ',\n",
    "' ICYMI ': ' In Case You Missed It ',\n",
    "' ICYWW ': ' In Case You Were Wondering ',\n",
    "' NBC ': ' Nobody Cares Though ',\n",
    "' NTW ': ' Not To Worry ',\n",
    "' OTD ': ' Of The Day ',\n",
    "' OOTD ': ' Outfit Of The Day ',\n",
    "' QOTD ': ' Quote of the Day ',\n",
    "' FOTD ': ' Find Of the Day ',\n",
    "' POIDH ': ' Pictures Or It Did ntt Happen ',\n",
    "' YOLO ': ' You Only Live Once ',\n",
    "' AFAIK ': ' As Far As I Know ',\n",
    "' DGYF ': ' Dang Girl You Fine ',\n",
    "' FWIW ': ' For What It is Worth ',\n",
    "' IDC ': ' I Do not Care ',\n",
    "' IDK ': ' I Do not Know ',\n",
    "' IIRC ': ' If I Remember Correctly ',\n",
    "' IMHO ': ' In My Honest Opinion ',\n",
    "' IMO ': ' In My Opinion ',\n",
    "' Jelly ': ' Jealous ',\n",
    "' Jellz ': ' Jealous ',\n",
    "' JSYK ': ' Just So You Know ',\n",
    "' LMAO ': ' Laughing My Ass Off ',\n",
    "' LMFAO ': ' Laughing My Fucking Ass Off ',\n",
    "' NTS ': ' Note to Self ',\n",
    "' ROFL ': ' Rolling On the Floor Laughing ',\n",
    "' ROFLMAO ': ' Rolling On the Floor Laughing My Ass Off ',\n",
    "' SMH ': ' Shaking My Head ',\n",
    "' TBH ': ' To Be Honest ',\n",
    "' TL;DR ':  ' Too Long; Did not Read ',\n",
    "' TLDR ':  ' Too Long; Did not Read ',\n",
    "' YGTR ': ' You Got That Right ',\n",
    "' AYKMWTS ': ' Are You Kidding Me With This Shit ',\n",
    "' BAMF ': ' Bad Ass Mother Fucker ',\n",
    "' FFS ': ' For Fuck Sake ',\n",
    "' FML ': ' Fuck My Life ',\n",
    "' HYFR ': ' Hell Yeah Fucking Right ',\n",
    "' IDGAF ': ' I Do not Give A Fuck ',\n",
    "' NFW ': ' No Fucking Way ',\n",
    "' PITA ': ' Pain In The Ass ',\n",
    "' POS ': ' Piece of Shit ',\n",
    "' SOL ': ' Shit Outta Luck ',\n",
    "' STFU ': ' Shut the Fuck Up ',\n",
    "' TF ': ' The Fuck ',\n",
    "' WTF ': ' What The Fuck ',\n",
    "' BFN ': ' Bye For Now ',\n",
    "' CU ': ' See You ',\n",
    "' IC ': ' I see ',\n",
    "' CYL ': ' See You Later ',\n",
    "' GTG ': ' Got to Go ',\n",
    "' OMW ': ' On My Way ',\n",
    "' RN ': ' Right Now ',\n",
    "' TTYL ': ' Talk To You Later ',\n",
    "' TYT ': ' Take Your time ',\n",
    "' CC ': ' Carbon Copy ',\n",
    "' CX ': ' Correction ',\n",
    "' DM ': ' Direct Message ',\n",
    "' FB ': ' Facebook ',\n",
    "' FBF ': ' Flash-Back Friday ',\n",
    "' FF ': ' Follow Friday ',\n",
    "' HT ': ' Tipping my hat ',\n",
    "' H/T ': ' Tipping my hat ',\n",
    "' IG ': ' Instagram ',\n",
    "' Insta ': ' Instagram ',\n",
    "' MT ':' Modified Tweet ',\n",
    "' OH ': ' Overheard ',\n",
    "' PRT ': ' Partial Retweet ',\n",
    "' RT ': ' Retweet ',\n",
    "'rt ' : ' retweet ',\n",
    "' SO ':' Shout Out ',\n",
    "' S/O ': ' Shout Out ',\n",
    "' TBT ': ' Throw-Back Thursday ',\n",
    "' AWOL ': ' Away While Online ',\n",
    "' BFF ': ' Best Friend Forever ',\n",
    "' NSFW ': ' Not Safe For Work ',\n",
    "' OG ': ' Original Gangster ',\n",
    "' PSA ': ' Public Service Announcement ',\n",
    "' PDA ': ' Public Display of Affection '}\n",
    "\n",
    "short = dict((key.lower(), value.lower()) for key,value in short.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Now let's replace the shortened words by their full alternatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "hidden": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Replacing shortened words with full words\n",
    "for word in short.keys():\n",
    "    df_train['message'] = df_train['message'].apply(lambda x: re.sub(word,short[word],x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**News handles**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Here is where we will now use our first created feature. We hope that by removing all handles that are **not** news related, we are helping the model distinguish between news and non news tweets. Where news related handles can be found inside our `news` list we created earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove twitter non news related handles and @ symbol\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r'@','', ' '.join([y for y in x.split() if y not in [z for z in re.findall(r'@[\\w]*',x) if z not in news]])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sentiment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "And now we will use the second feature we created. As explained earlier, we hope that by adding sentiment words (`negative`,`positive`,`neutral`) to the text, we are helping the model distinguish between the classes `Anti`, `Pro` and `Neutral`. We apply this transformation before removing punctuation, since punctuation like exclamation marks (`!`) are of great value during sentiment analysis. Depending on the computer you have the code below might take a minute to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Add sentiment\n",
    "df_train['message'] = df_train['message'].apply(lambda x: x + ' ' + sentiment_score(x))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Punctuation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Other than with sentiment analysis, where some punctuation is useful, punctuations, symbols and numbers tend to be rendered useless in modeling. As they are not specific to certain classes, they add no explanatory power and can therefore be removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove punctuation\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r\"[^A-Za-z ]*\",'',x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Vowels repeated at least 3 times**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is not uncommon for people to stretch words when typing. For example, instead of using `cool` the word is stretched to `cooooool`. Words are of no use to us in this form, so we wish to shrink them back to their appropriate size. We'll do this by removing any extra vowels that are repeated at least three times. Note that we are aware that words like `nooooo` should be reduced to only one vowel to result in `no`. The reason we reduce to two vowels is to reduce the probability of creating misspelled words that could mean something else in their transformed form. A good example would be `beeeee`. Where `bee` and `be` would mean two completely different things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Remove vowels repeated at least 3 times ex. Coooool > Cool\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r'([aeiou])\\1+', r'\\1\\1', x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Sequences indicating laughing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "It is also very common for people to express laughter in different ways. A few of these ways are in fact just a sequence of repeating letters like `haha` or `lolol`. For these sequences to add more value to our model we'll change them to the word `laugh`, which the model can easily understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replace sequence of 'h' and 'a', as well as 'lol' with 'laugh'\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r' ha([ha]) *', r'laugh', x))\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r' he([he]) *', r'laugh', x))\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r' lol([ol]) *', r'laugh', x))\n",
    "df_train['message'] = df_train['message'].apply(lambda x: re.sub(r' lo([o])*l ', r'laugh', x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Cleaning function**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Tweets can have a lot of noise in them from the type of language, style and grammar used. All things the computer may find hard to process. These issues have to be dealt with in order for the model to be able to process the text data and make predictions. We'll write a function (`cleanup`) to apply all the necessary transformations that we applied and explained above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def cleanup(raw):\n",
    "    \"\"\" A function that 'cleans' tweet data. The text gets modified by:\n",
    "        - being lower cased, \n",
    "        - removing urls, \n",
    "        - removing bad unicode,\n",
    "        - replacing emojis with words,\n",
    "        - removing twitter non news related handles,\n",
    "        - removing punctuation,\n",
    "        - removing vowels repeated at least 3 times,\n",
    "        - replacing sequences of 'h' and 'a', as well as 'lol' with 'laugh',\n",
    "        - adding sentiment\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        raw: Text string.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        raw:  Modified clean string\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert to lowercase\n",
    "    raw = raw.lower()\n",
    "    \n",
    "    # Fix strange characters\n",
    "    raw = fix_text(raw)\n",
    "    \n",
    "    # Removing urls\n",
    "    raw = re.sub(r'https\\S+','url',raw)\n",
    "    raw = re.sub(r'www\\S+', 'url',raw)\n",
    "    \n",
    "    # Replace emojis with their word meaning\n",
    "    raw = emoji.demojize(raw)\n",
    "\n",
    "    # Remove twitter non news related handles\n",
    "    raw = ' '.join([y for y in raw.split() if y not in [x for x in re.findall(r'@[\\w]*',raw) if x not in news]])\n",
    "    \n",
    "    # Add sentiment\n",
    "    raw = raw + ' ' + sentiment_score(raw)\n",
    "    \n",
    "    # Remove punctuation\n",
    "    raw = re.sub(r\"[^A-Za-z ]*\",'',raw)\n",
    "    \n",
    "    # Remove vowels repeated at least 3 times ex. Coooool > Cool\n",
    "    raw = re.sub(r'([aeiou])\\1+', r'\\1\\1', raw)\n",
    "    \n",
    "    # Replace sequence of 'h' and 'a', as well as 'lol' with 'laugh'\n",
    "    raw = re.sub(r' ha([ha]) *', r'laugh', raw)\n",
    "    raw = re.sub(r' he([he]) *', r'laugh', raw)\n",
    "    raw = re.sub(r' lol([ol]) *', r'laugh', raw)\n",
    "    raw = re.sub(r' lo([o])*l ', r'laugh', raw)\n",
    "    \n",
    "    return raw\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To be able to make somewhat accurate predictions we need to apply all the above transformations to our testing set `df_test` as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Seperate hashtags\n",
    "df_test = expand_hashtags(df_test,'message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replace contracted words with full word\n",
    "df_test['message'] = [' '.join([contractions[w.lower()] if w.lower() in contractions.keys() else w for w in raw.split()]) for raw in df_test['message']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Replacing shortened words with full words\n",
    "for word in short.keys():\n",
    "    df_test['message'] = df_test['message'].apply(lambda x: re.sub(word,short[word],x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Apply cleaning function\n",
    "df_test['message'] = df_test['message'].apply(lambda x: cleanup(x))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Spelling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We also check the percentage of misspelled words in the data, so we can know if this is also an issue that needs to be fixed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spell = SpellChecker() \n",
    "# check for misspelled words\n",
    "misspelled = df_train['message'].apply(lambda x: spell.unknown(x))\n",
    "misspelled.isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like we do not have misspelled words after cleaning.  \n",
    "\n",
    "*Great!* We've finished cleaning our data. We can now move on to exploring the data, splitting the data and training our models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Exploratory data analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's first get quick overview of the dataset we will be working with throughout the notebook. Below is the shape of the dataset, a list of all columns with their data types and the number of non-null values present in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data: (15819, 2)\n"
     ]
    }
   ],
   "source": [
    "# Data shape\n",
    "print('train data:',df_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15819 entries, 625221 to 806319\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   sentiment  15819 non-null  int64 \n",
      " 1   message    15819 non-null  object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 309.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are only two columns present in the training dataset; the label variable we want to classify to (`'sentiment'`), and the feature we will use to make this classification (`'message'`). We initially had a third column (`'tweetid'`) but set this column to be the index of the dataset.  The dataset contains no null entries, and the data types for (`'sentiment'`) and (`'message'`) are integer and object respectively. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Missing values**  \n",
    "\n",
    "If we look at the output above, we can see that there does not seem to be any missing values present. The dataset has **15819** entries and both columns have the same amount of non-null entries. But since an empty string for tweets can also be considered as a missing entry, we need to check for empty strings in the `message` column as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for empty strings\n",
    "blanks = [i for i,lb,tweet in df_train.itertuples() if type(tweet) == str if tweet.isspace()]\n",
    "blanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The list is empty, indicating that there are no empty strings and therefore no missing values present in the dataset.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Duplicates**  \n",
    "\n",
    "Another thing we need to look out for are duplicates. A large amount of duplicates in the data tend to increase the bias of the estimated coefficients and standard errors of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment    12.548202\n",
       "message      12.548202\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for duplicates in tweets\n",
    "df_train[df_train.duplicated(subset='message') == True].count()/len(df_train)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Roughly 12% of the tweets seem to be duplicated tweets but with different ID's. Since we don't have a significantly large amount of data we will keep these duplicates and later check the impact they have when fitting the models.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[VADER](https://medium.com/analytics-vidhya/simplifying-social-media-sentiment-analysis-using-vader-in-python-f9e6ec6fc52f) (Valence Aware Dictionary and sEntiment Reasoner) is a lexicon and rule-based sentiment analysis tool that is specifically attuned to sentiments expressed in text data. It provides sentiment scores based on words used (\"completely\" boosts a score, while \"slightly\" reduces it), on capitalization & punctuation (\"GREAT!!!\" is stronger than \"great.\")\n",
    "\n",
    "Next we will analyse our text data using the `Vader` sentiment analysis polarity score, to get a view of our negative,neutral and positive tweets before we perform any analysis. We use the compound score output of vader, which is a metric that calculates the sum of all the lexicon ratings which have been normalized between -1(most extreme negative) and +1 (most extreme positive).\n",
    "Note: We will be working on a copy of the train dataset to preserve it from the modifications done to it during this exploratory data analysis process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>compound</th>\n",
       "      <th>comp_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweetid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>625221</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126103</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>0.1159</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573736</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>-0.5994</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466954</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>-0.7506</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425577</th>\n",
       "      <td>1</td>\n",
       "      <td>Worth a read whether you do or don't believe i...</td>\n",
       "      <td>0.2263</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment                                            message  \\\n",
       "tweetid                                                                 \n",
       "625221           1  PolySciMajor EPA chief doesn't think carbon di...   \n",
       "126103           1  It's not like we lack evidence of anthropogeni...   \n",
       "573736           1  #TodayinMaker# WIRED : 2016 was a pivotal year...   \n",
       "466954           1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   \n",
       "425577           1  Worth a read whether you do or don't believe i...   \n",
       "\n",
       "         compound comp_score  \n",
       "tweetid                       \n",
       "625221     0.2244        pos  \n",
       "126103     0.1159        pos  \n",
       "573736    -0.5994        neg  \n",
       "466954    -0.7506        neg  \n",
       "425577     0.2263        pos  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sid = SentimentIntensityAnalyzer()\n",
    "df_sent = df_train_eda.copy()\n",
    "df_sent['compound']  =  df_sent['message'].apply(lambda x: sid.polarity_scores(x)['compound'])\n",
    "df_sent['comp_score'] = df_sent['compound'].apply(lambda c: 'pos' if c >0 else 'neg' if c<0 else 'neu')\n",
    "df_news = df_sent[df_sent['sentiment']==2] #extract all news and separate them from positive,neut and neg\n",
    "df_analyse = df_sent[df_sent['sentiment'] != 2]\n",
    "df_analyse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the 5 most positive tweets(i.e Pro: Believes in man-made climate change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m 5 random tweets with the highest positive sentiment: \\033[0m \\n')\n",
    "tweets = df_analyse.loc[df_analyse['compound'] > 0.8, ['message']].sample(5).values\n",
    "for c in tweets:\n",
    "    print(c[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at the 5 most negative tweets(i.e Anti: Does not believe in man-made climate change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m 5 random tweets with the highest negative sentiment: \\033[0m \\n')\n",
    "tweets = df_analyse.loc[df_analyse['compound'] < -0.8, ['message']].sample(5).values\n",
    "for c in tweets:\n",
    "    print(c[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets look at 5 neutral tweets(i.e Neutral: Neither supports nor refutes belief of man-made climate change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m 5 random tweets with the neutral sentiment: \\033[0m \\n')\n",
    "tweets = df_analyse.loc[df_analyse['compound'] == 0, ['message']].sample(5).values\n",
    "for c in tweets:\n",
    "    print(c[0])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lastly we will look at 5 news related tweets(i.e News: Factual news about climate change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\033[1m 5 random tweets from news: \\033[0m \\n')\n",
    "tweets = df_news['message'].sample(5).values\n",
    "for c in tweets:\n",
    "    print(c)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next we will have a look at the most common words in tweets with highest sentiment, for each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "df_pro = df_train.loc[df_train['sentiment'] ==1, ['message']]\n",
    "df_anti = df_train.loc[df_train['sentiment'] ==-1, ['message']]\n",
    "df_neutral = df_train.loc[df_train['sentiment'] ==0, ['message']]\n",
    "df_news=df_train.loc[df_train['sentiment']==2, ['message']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "p= (' '.join(df_pro['message']))\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500,max_words=50,background_color=\"white\",colormap=\"gist_earth\").generate(p)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.figtext(.5,.9,'Common words in Pro class: \"Believes in man-made climate change\"\\n',fontsize=14, ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "a= (' '.join(df_anti['message']))\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500,max_words=50,background_color=\"white\",colormap=\"gist_earth\").generate(a)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.figtext(.515,.9,'Common words in Anti class: \"Does not believe in man-made climate change\"\\n',fontsize=14, ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "n= (' '.join(df_neutral['message']))\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500,max_words=50,background_color=\"white\",colormap=\"gist_earth\").generate(n)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.figtext(.515,.9,'Common words in Neutral class: \"Neither supports nor refutes belief of man-made climate change\\n\"',fontsize=14, ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "nw= (' '.join(df_news['message']))\n",
    "\n",
    "wordcloud = WordCloud(width = 1000, height = 500,max_words=50,background_color=\"white\",colormap=\"gist_earth\").generate(nw)\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.figtext(.515,.9,'Common words in News class: \"Factual news about climate change\"\\n',fontsize=14, ha='center')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "From these word clouds we can see some of the most common words that are used in tweets with the highest sentiment in each class.This gives us some sort of indication on the type of words a tweet with certain sentiment might have. For example, in our outputs above Pro class has words and phrases like *love*, *building new*, *new earth* and Anti has words and phrases like *die*, *doesn't believe*. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will look at the distribution of the sentiment scores to see the overall distribution of the sentiment in our tweets data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#proportion of the negative positive and neutral sentiments.\n",
    "df_analyse['comp_score'].replace({1:'positive',0:'neutral',-1:'negative'}).value_counts()/len(df_analyse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15, 4))\n",
    "plt.figtext(.51,.95, 'Distribution of sentiment scores\\n', fontsize=20, ha='center',fontweight='bold')\n",
    "\n",
    "ax1.hist(df_analyse['compound'], bins=15, edgecolor='k',color='lightblue')\n",
    "plt.figtext(0.23, 0.06, 'sentiment score\\n', horizontalalignment='left',fontsize = 12)\n",
    "fig.text(0.00001, 0.5, 'number of tweets', va='center', rotation='vertical',fontsize=12)\n",
    "plt.figtext(0.10, 0.0001, 'figure 1: positive, negative and neutral sentiment', horizontalalignment='left',fontsize = 14,style='italic')\n",
    "\n",
    "bins = np.linspace(-1, 1, 30)\n",
    "ax2.hist([df_analyse['compound'][df_analyse['compound'] > 0], df_analyse['compound'][df_analyse['compound'] < 0]], bins, label=['Positive sentiment', 'Negative sentiment'])\n",
    "plt.xlabel('sentiment score\\n',fontsize=12)\n",
    "ax2.legend(loc='upper right')\n",
    "plt.figtext(0.90, 0.0001, 'figure 2: positive and negative sentiment', horizontalalignment='right',fontsize = 14,style='italic')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In *figure 1* we can see that the data has a somewhat symmetric shape indicating uniformity in our data with a spike at 0(i.e neutral). The spike indicates that more data falls in that range, i.e most of our tweets were assigned a neutral sentiment. This makes sense since all the neutral data was packed into the 0 range,whereas the positive and negative sentiments where distributed in the ranges [-1:0) and (0:1], respectively\n",
    "\n",
    "In *figure 2* we only look a the positive(right) and negative(left) sentiments. The positive sentiment has less tweets with sentiment greater that 0.5(i.e high positive sentiment), whereas negative sentiment has significantly more tweets below -0.5(i.e high negative sentiment)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent['sentiment'] = df_sent['sentiment'].replace({2:'News',1:'Pro',0:'Neutral',-1:'Anti'})\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.boxplot(x='sentiment', y='compound' , data= df_sent)\n",
    "plt.title('Distribution of the sentiment scores for all classes',fontsize = 14)\n",
    "plt.xlabel('sentiment score', fontsize = 10)\n",
    "plt.figtext(0.12, 0.00000001, 'figure 3: Distribution of positive, negative and neutral sentiment scores', horizontalalignment='left',\n",
    "            fontsize = 14,style='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the overall distribution of the sentiment score for the tweets data, *figure 3* shows a left skewed distribution. This is indicating that most of the tweets are scored with a negative sentiment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will have a look at the different labels we will be classifying to. We know that our data is classified to four unique classes (*News*, *Pro*, *Neutral*, *Anti*). Let us have a look at the data associated with each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "names = ['Pro','News','Neutral','Anti']\n",
    "perc = df_train['sentiment'].replace({-1: 'Anti',0:'Neutral',1:'Pro',2:'News'}).value_counts()\n",
    "perc.name = ''\n",
    "perc.plot(kind='pie', labels=names, autopct='%1.1f%%')\n",
    "plt.title('Proportion of tweets in each class',fontsize = 16)\n",
    "plt.figtext(0.12, 0.1, 'figure 4: Percentage of tweets that are classified as either Anti, Pro, Neutral and News',\n",
    "            horizontalalignment='left',fontsize = 14,style='italic')\n",
    "plt.legend(df_train['sentiment'].replace({-1: 'Anti: Does not believe in man-made climate change',\n",
    "                                          0:'Neutral: Neither believes nor refutes man-made climate change',\n",
    "                                          1:'Pro:Believe in man-made climate change',\n",
    "                                          2:'News: Factual News about climate change'}).value_counts().index,\n",
    "           bbox_to_anchor=(2.3,0.7), loc=\"right\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examining *figure 4* and *figure 5* it is apparent that the majority of the tweets(53.9%) are classified as Pro, i.e. supports the belief of man-made climate change, and the minority of the tweets(8.2%) are classified as Anti, i.e Does not believe in man made climate change. Tweets classified as Pro are 6.6 times more than those classified as AntiTweets classified as Pro are 6.6 times more than those classified as Anti. There is a signican imbalance between the two groups.\n",
    "Unbalanced data is a problem, in that, the model might perform well in classifying the larger class but do poorly in classifying the smaller classes. So we can expect that the classification algorithm will perform better when classifying larger classes ( _Pro_ ) than the smaller classes ( _News, Neutral, Anti_ ). \n",
    "In our case knowing when a tweet has a sentiment that is Anti man-made climate change has an impact on how that customer may perceive a product. So if the model will mostly sentiment as Pro  man made climate change, it could classify some of the anti as pro which gives a skewed idea about customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "To deal with unbalanced data one can apply resampling to the classes by adjusting the number of observations in the classes. There are 3 types of resampling:\n",
    "\n",
    "    1.Upsampling: Taking repeated random samples from the minority class until we have as many observations as the majority           class. This duplicates observations in the minority class at random\n",
    "    \n",
    "    2.Downsampling: Taking a random subset of the majority class small enough to match the number of observations in the             minority class. This then reduces the number of observations in the majority class.\n",
    "    \n",
    "    3.Both: You can apply both of these resampling methods by deciding on a class_size(usually half of major class) and               setting a threshold of 50% where classes above this threshold are downsampled and classes below this threshold are             upsampled\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have then created a funtion To deal with the uneven distribution of class labels. The function will modify the number of observations for a class(es) we need to resample. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create resampling function\n",
    "def resampling(df, class1, class2):\n",
    "    \"\"\" A function takes in a dataframe, a class to be resampled, and a class \n",
    "        thats observations are to be matched with.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        df:     Dataframe to be resampled.\n",
    "        class1: Integer of the class that is to be resampled.\n",
    "        class2: Integer of the class whose length is used to resample class1.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        df_resampled:  Resampled dataframe.\n",
    "    \"\"\"\n",
    "    df_class1= df[df.sentiment==class1]\n",
    "    df_class2 = df[df.sentiment==class2]\n",
    "    df_new= df[df.sentiment!=class1]\n",
    "    resampled = resample(df_class1, replace=False, n_samples=len(df_class2), random_state=27)\n",
    "    df_resampled = pd.concat([resampled, df_new])    \n",
    "    return df_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Having a look at the distribution of word counts per class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent['count'] = df_sent['message'].apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Kernel distribution of number of words per class',fontsize = 14)\n",
    "sns.kdeplot(df_sent['count'][df_sent['sentiment']=='Pro'], shade=True, color='g',legend=False)\n",
    "sns.kdeplot(df_sent['count'][df_sent['sentiment']=='Neutral'], shade=True, color='b',legend=False)\n",
    "sns.kdeplot(df_sent['count'][df_sent['sentiment']=='Anti'], shade=True, color='r',legend=False)\n",
    "sns.kdeplot(df_sent['count'][df_sent['sentiment']=='News'], shade=True, color='orange',legend=False)\n",
    "plt.legend(title='Sentiment class', loc='upper right', labels=['Pro', 'Neutral', 'Anti', 'News'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.title('Kernel distribution of number of words per sentiment category',fontsize = 14)\n",
    "sns.kdeplot(df_sent['count'][df_sent['comp_score']=='pos'], shade=True, color='g',legend=False)\n",
    "sns.kdeplot(df_sent['count'][df_sent['comp_score']=='neu'], shade=True, color='b',legend=False)\n",
    "sns.kdeplot(df_sent['count'][df_sent['comp_score']=='neg'], shade=True, color='r',legend=False)\n",
    "plt.legend(title='Sentiment score', loc='upper right', labels=['Positive', 'Neutral', 'Negative'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row0_col1 {\n",
       "            background-color:  #00441b;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row1_col1 {\n",
       "            background-color:  #005120;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row2_col1 {\n",
       "            background-color:  #026f2e;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row3_col1 {\n",
       "            background-color:  #05712f;\n",
       "            color:  #f1f1f1;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row4_col1 {\n",
       "            background-color:  #5db96b;\n",
       "            color:  #000000;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row5_col1 {\n",
       "            background-color:  #63bc6e;\n",
       "            color:  #000000;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row6_col1 {\n",
       "            background-color:  #e9f7e5;\n",
       "            color:  #000000;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row7_col1 {\n",
       "            background-color:  #f5fbf3;\n",
       "            color:  #000000;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row8_col1 {\n",
       "            background-color:  #f6fcf4;\n",
       "            color:  #000000;\n",
       "        }    #T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row9_col1 {\n",
       "            background-color:  #f7fcf5;\n",
       "            color:  #000000;\n",
       "        }</style><table id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Most common words</th>        <th class=\"col_heading level0 col1\" >Count</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row0_col0\" class=\"data row0 col0\" >climate</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row0_col1\" class=\"data row0 col1\" >3800</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row1_col0\" class=\"data row1 col0\" >change</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row1_col1\" class=\"data row1 col1\" >3663</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row2_col0\" class=\"data row2 col0\" >rt</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row2_col1\" class=\"data row2 col1\" >3328</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row3_col0\" class=\"data row3 col0\" >https</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row3_col1\" class=\"data row3 col1\" >3304</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row4_col0\" class=\"data row4 col0\" >global</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row4_col1\" class=\"data row4 col1\" >2252</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row5_col0\" class=\"data row5 col0\" >warming</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row5_col1\" class=\"data row5 col1\" >2199</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row6_col0\" class=\"data row6 col0\" >trump</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row6_col1\" class=\"data row6 col1\" >652</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row7_col0\" class=\"data row7 col0\" >amp</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row7_col1\" class=\"data row7 col1\" >355</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row8_col0\" class=\"data row8 col0\" >real</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row8_col1\" class=\"data row8 col1\" >342</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row9_col0\" class=\"data row9 col0\" >believe</td>\n",
       "                        <td id=\"T_a3661ed8_b8b8_11ea_bdf4_3859f9d5d279row9_col1\" class=\"data row9 col1\" >306</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x28206850>"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pro tweets\n",
    "vecp = CountVectorizer(stop_words='english')\n",
    "count_vecp = vecp.fit_transform(df_sent['message'][df_sent['comp_score']=='pos'])\n",
    "c_words_p = count_vecp.sum(axis=0) \n",
    "wordcountp = [(w, c_words_p[0, i]) for w, i in vecp.vocabulary_.items()]\n",
    "wordcountp =sorted(wordcountp, key = lambda x: x[1], reverse=True)\n",
    "\n",
    "pd.DataFrame(wordcountp[:10],columns=['Most common words','Count']).style.background_gradient(cmap='Greens')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we look at the ditribution of the labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt = df_train['sentiment'].value_counts().rename_axis('sentiment').reset_index(name='number of tweets')\n",
    "di = {-1: '-1: Anti',0:'0: Neutral',1:'1: Pro',2:'2: News'}\n",
    "cnt['sentiment'].replace(di, inplace=True)\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2,figsize=(15, 4))\n",
    "plt.figtext(.51,.95, 'Distribution of the number of tweets on the classes Anti, Pro, Neutral and News\\n', fontsize=16, ha='center')\n",
    "\n",
    "ax1.boxplot(cnt['number of tweets'], widths = 0.3, vert=False, patch_artist=True)\n",
    "plt.xlabel('Number of tweets per sentiment class')\n",
    "# ax.set_xlabel('Number of tweets per sentiment class')\n",
    "plt.yticks([1],[''])\n",
    "\n",
    "font_size=14\n",
    "bbox=[0, 0, 1, 1]\n",
    "ax2.axis('off')\n",
    "mpl_table = ax2.table(cellText = cnt.values, rowLabels = cnt.index, bbox=bbox, colLabels=cnt.columns)\n",
    "mpl_table.auto_set_font_size(False)\n",
    "mpl_table.set_fontsize(font_size)\n",
    "\n",
    "plt.figtext(0.1, 0.0005, 'figure 6: Distribution of the classification( Anti, Pro, Neutral and News) classes based on the number of tweets in each class',\n",
    "            horizontalalignment='left',\n",
    "            fontsize = 14,style='italic')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Figure 6* indicates a skewness to the right. This indicates further that the data consists of more Pro tweets than Anti tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split data into response and predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Next we split our data into response (Y) and predictor variables (X). We will use the predictor to fit a model that can somewhat accurately classify a tweet. The response variable will be used to validate/test our predictions. Our predictor variable would be our `message` column and our response variable would be what we want to predict, which is the `sentiment` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "y = df_train['sentiment']\n",
    "X = df_train['message']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Split data into training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The ultimate goal of fitting our machine learning models is to make relatively accurate classifications on unseen data. This is data we don't have at our disposal. So to measure the performance of our model we want to test it on unseen data as well. This is why we create a validation or testing set.  \n",
    "\n",
    "- Training sets: The samples of data the model uses for learning  \n",
    "- Testing sets: The samples of data used to assess the model's performance.\n",
    "\n",
    "We chose to use 80% of the data for training and 20% was kept aside for validation. The observations for these datasets are selected at random. This ensures that the mix of data in the train set is as close as possible to the mix in the validation/test set.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we are going to transform our text data into something that the computer can understand and use for modeling.  \n",
    "\n",
    "But first we will explore stopwords, n-grams and the impact they have on some baseline model. We chose logistic regression to evaluate the impact of these features on our overall model accuracy. This model was chosen due to it being scalable to large data and also being one of the more computationally efficient models.  \n",
    "\n",
    "We start by extracting features from text data using `TfidfVectorizer()`. The tfidf vectorizer learns vocabulary from the text data and then proceeds to tokenize and create feature vectors from the text. Each tweet is then represented by a unique vector depending on its tokens, where the columns inside the vectors represent the features (which is the different words in the vocabulary) and the values represent the count of each word present in the tweet. See the illustration below.  \n",
    "\n",
    "<img src=\"Vectorize1.png\" style=\"width:800px;height:500px\">\n",
    "\n",
    "And voila! We have transformed text into a form that computers can understand. All these vectors are then transformed to contain tfidf(term frequency–inverse document frequency) scores instead of these counts. Tfidf is a numerical statistic that is intended to reflect how important a word is to a document (tweet in our case). It works by proportionally increasing to the number of times a word appears in a document (tweet), but is offset by the number of documents that contain the word. So words like 'you, 'this' and 'and' rank low even though they may appear many times. This is because they do not mean that much to the document. On the other hand, words like 'armadillo' would have a higher ranking since we assume that a word is very relevant to the given document if it does not appear in many other documents. \n",
    "\n",
    "Often in languages we have different versions of words that have the same core meaning. Examples would be 'run', 'ran' and 'running'. All three those word essentially refer to the action of running, just in different times. There is a method called stemming that reduces words to their base form. So essentially, after applying this method, all three of the words above would be reduced to the word 'run'. Python's nltk library has a method (`SnowballStemmer()`) that does exactly this for us. We will now write a class that will stem and tokenize text data and use this as a parameter in our vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write class that has object that tokenizes text data AND stems the tokens\n",
    "class StemAndTokenize:\n",
    "    def __init__(self):\n",
    "        self.ss = SnowballStemmer('english')\n",
    "    def __call__(self, doc):\n",
    "        return [self.ss.stem(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stopwords  \n",
    "\n",
    "First we'll look at stopwords using **unigrams**. Stopwords are common words that, due to their frequency in all sentences of any class, could be seen as insignificant. These are words like 'the', 'and', 'with', 'for', 'you' and 'I'. It is often assumed that removing stopwords improves a model's performance. But since tweets tend to be very short, with a maximum of only 280 characters, we want to test whether removing them could possibly reduce model accuracy instead.  \n",
    "\n",
    "Let's create two different feature matrices, one containing stopwords and one with stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "# Stopwords included\n",
    "SW_vec_uni = TfidfVectorizer(tokenizer=StemAndTokenize())\n",
    "SW_X_uni = SW_vec_uni.fit_transform(X_train)\n",
    "\n",
    "# Stopwords excluded\n",
    "noSW_vec_uni = TfidfVectorizer(stop_words='english', tokenizer=StemAndTokenize())\n",
    "noSW_X_uni = noSW_vec_uni.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a logistic regression model to both these feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords included\n",
    "SW_uni = LogisticRegression()\n",
    "SW_uni.fit(SW_X_uni,y_train)\n",
    "\n",
    "# Stopwords excluded\n",
    "noSW_uni = LogisticRegression()\n",
    "noSW_uni.fit(noSW_X_uni,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at both the accuracy score and F1 score when using these trained models to predict the sentiment of tweets. Since our test set serves as our unseen data we do not fit the vectorizer to the test set, we only transform it with the vectorizer fit to the corresponding train set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== Stopwords included ======\n",
      "Accuracy: 0.7402022756005057 \n",
      "F1-score: 0.7191664897915931\n",
      "\n",
      "\n",
      "====== Stopwords excluded ======\n",
      "Accuracy: 0.7354614412136536 \n",
      "F1-score: 0.7123380136033697\n"
     ]
    }
   ],
   "source": [
    "# Stopwords included\n",
    "SW_uni_pred = SW_uni.predict(SW_vec_uni.transform(X_test))\n",
    "print('====== Stopwords included ======')\n",
    "print(f'Accuracy: {accuracy_score(y_test, SW_uni_pred)} \\nF1-score: {f1_score(y_test, SW_uni_pred, average=\"weighted\")}')\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Stopwords excluded\n",
    "noSW_uni_pred = noSW_uni.predict(noSW_vec_uni.transform(X_test))\n",
    "print('====== Stopwords excluded ======')\n",
    "print(f'Accuracy: {accuracy_score(y_test, noSW_uni_pred)} \\nF1-score: {f1_score(y_test, noSW_uni_pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Albeit a small difference, the model containing stopwords seems to perform better. This will probably be the case for other models as well. After optimizing hyperparameters later on, this difference could possibly be even larger. So we conclude that it would be wise to keep stopwords inside the text data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### N-grams\n",
    "\n",
    "Next we compare the model above with models that use bigrams and trigrams. N-grams are all possible combinations of adjacent words of length n in text (*or in our case a tweet*). Let us illustrate this using an example.  \n",
    "\n",
    "> *Text:*  \n",
    "`'The brown fox jumps over the gate'`  \n",
    "***\n",
    "> *List of bigrams (n-grams where n=2):*  \n",
    "`['The brown', 'brown fox', 'fox jumps', 'jumps over', 'over the', 'the gate']`  \n",
    "\n",
    "N-grams are used to capture the language structure of the text. They look at how likely it is for a letter or word to follow another one. The longer the n-gram (the larger the value of n), the more context you have to work with. N-grams are known to increase a model's accuracy, but generally we do not want n-grams to be too long, since they would start becoming counterproductive.  \n",
    "\n",
    "Now we create two different feature matrices, one using bigrams and one using trigrams. Both of these models will **not** have stopwords removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bigrams\n",
    "SW_vec_bi = TfidfVectorizer(tokenizer=StemAndTokenize(), ngram_range=(2, 2))\n",
    "SW_X_bi = SW_vec_bi.fit_transform(X_train)\n",
    "\n",
    "# Trigrams\n",
    "SW_vec_tri = TfidfVectorizer(tokenizer=StemAndTokenize(), ngram_range=(3, 3))\n",
    "SW_X_tri = SW_vec_tri.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we fit a logistic regression model to both these feature matrices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bigrams\n",
    "SW_bi = LogisticRegression()\n",
    "SW_bi.fit(SW_X_bi,y_train)\n",
    "\n",
    "# Trigrams\n",
    "SW_tri = LogisticRegression()\n",
    "SW_tri.fit(SW_X_tri,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at both the accuracy score and F1 score when using these trained models to predict the sentiment of tweets. We will add the unigram model here again for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========== Unigrams ==========\n",
      "Accuracy: 0.7402022756005057 \n",
      "F1-score: 0.7191664897915931\n",
      "\n",
      "\n",
      "========== Bigrams ==========\n",
      "Accuracy: 0.7098609355246523 \n",
      "F1-score: 0.6752124717719953\n",
      "\n",
      "\n",
      "========== Trigrams ==========\n",
      "Accuracy: 0.6665613147914032 \n",
      "F1-score: 0.6192155186320547\n"
     ]
    }
   ],
   "source": [
    "# Unigrams\n",
    "SW_uni_pred = SW_uni.predict(SW_vec_uni.transform(X_test))\n",
    "print('========== Unigrams ==========')\n",
    "print(f'Accuracy: {accuracy_score(y_test, SW_uni_pred)} \\nF1-score: {f1_score(y_test, SW_uni_pred, average=\"weighted\")}')\n",
    "print()\n",
    "print()\n",
    "      \n",
    "# Bigrams\n",
    "SW_bi_pred = SW_bi.predict(SW_vec_bi.transform(X_test))\n",
    "print('========== Bigrams ==========')\n",
    "print(f'Accuracy: {accuracy_score(y_test, SW_bi_pred)} \\nF1-score: {f1_score(y_test, SW_bi_pred, average=\"weighted\")}')\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Trigrams\n",
    "SW_tri_pred = SW_tri.predict(SW_vec_tri.transform(X_test))\n",
    "print('========== Trigrams ==========')\n",
    "print(f'Accuracy: {accuracy_score(y_test, SW_tri_pred)} \\nF1-score: {f1_score(y_test, SW_tri_pred, average=\"weighted\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output we see that the model using bigrams seems to outperform the model using trigrams. But overall the model using unigrams reigns supreme.  \n",
    "\n",
    "So after examining the impact of both stopwords and n-grams we conclude that a model using unigrams and containing stopwords would be the better choice. We will use these parameter values for the vectorizers for all our models from this moment on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the amount of code we use, we will be using pipelines that will both vectorize the text data and create our different models. In the spirit of killing two birds with one stone, let's add another and add the method `GridSearchCV()` to the pipeline. This method is used to optimize some parameters for each of the models we want to train. And we will be using cross validation to determine the best combination of parameters. An explanation will follow, but this image describes it nicely:  \n",
    "\n",
    "<img src=\"cv.png\" style=\"width:800px;height:500px\">\n",
    "\n",
    "According to an [article](https://machinelearningmastery.com/k-fold-cross-validation/#:~:text=Cross%2Dvalidation%20is%20a%20resampling,k%2Dfold%20cross%2Dvalidation.) by Machine Learning Mastery, cross-validation is a statistical method used to estimate the skill of machine learning models. We have already split our data into training and testing sets, but here we will do another split on our training set. As we can see from the image above, a certain percentage (we chose 10%) of the training data will be kept aside for validation purposes. We essentially train the model on 90% of the train set and using the rest of the 10% to calculate some accuracy statistic of our choice. This process is then repeated a number of times and in our case we are choosing a 10 fold split. Each repeat will have a different combination of the train set for training and validation. And finally we aggregate over all the statistics for our final accuracy statistic. \n",
    "\n",
    "The parameters that will be optimized, however, will differ from model to model, but we'll discuss our choices further below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The first model we're going to look at is Logistic regression. For this model and all the following models, we are using 10-fold crossvalidation (`cv=10`) and specifying the parameter `n_jobs=-1` so we can use all processors when applying the gridsearch method. In some cases we will also be setting `random_state=42` so we can compare the performance of our different models.  \n",
    "\n",
    "For logistic regression we are only going to look at the C parameter. It’s a penalty term, meant to disincentivize and regulate against overfitting. The parameter indicates the inverse of regularization strength, i.e. smaller values specify stronger regularization. So we will be looking which size of C yields the best results. \n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# parameters to be tested for Logistic Regression\n",
    "param_grid_lr = {'C':[0.01, 0.1, 1, 5, 10, 20]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline for Logistic Regression:\n",
    "lr = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('lr', GridSearchCV(LogisticRegression(),\n",
    "                                   param_grid=param_grid_lr,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "**Naïve Bayes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For the naïve bayes classifier we will also only be looking at one parameter. `alpha` is the regularization parameter for the naïve bayes classifier and is known as the smoothing parameter.  \n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# parameters to be tested for Naïve Bayes\n",
    "param_grid_nb = {'alpha':[0.001, 0.01, 0.1, 1, 5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline for Naïve Bayes:\n",
    "nb = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('nb', GridSearchCV(MultinomialNB(),\n",
    "                                   param_grid=param_grid_nb,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "**SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For support vector machines we will be trying to optimize three parameters. Once again we'll have a look at the C parameter we explained above, along with the `kernel` and `gamma` parameters. Kernel methods are a class of algorithms used to detect and study patterns in data. We'll look at the linear kernel as well as the radial basis function (rbf) kernel. The `gamma` parameter indicates the kernel coefficient for the rbf kernel and we'll look at the options 'scale' and 'auto'.\n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# parameters to be tested for SVM\n",
    "param_grid_svm = {'C':[50, 100, 150, 200],\n",
    "                  'kernel':['linear', 'rbf'],\n",
    "                  'gamma':['scale','auto']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline for SVM:\n",
    "svm = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('svm', GridSearchCV(SVC(random_state=42),\n",
    "                                   param_grid=param_grid_svm,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the random forest classifier we will be looking at four different parameter. `max_features` indicates the maximum number of features to consider when looking for the best split. By reducing the number of features each tree in a random forest can use to fit a model, we improve the model. This is simply due to the model now being able to test a lot of different combinations of variables, rather than fitting a model using all the features every time. `n_estimators` indicate the number of trees that we want in the forest and `max_depth` indicate the maximum depth of a single tree. And finally we also look at `criterion` which indicates the function to be used to measure the quality of a split.  \n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters to be tested for Random Forest\n",
    "param_grid_rf = {'max_features':[0.5,'log2'],\n",
    "                 'n_estimators':[50,75,100],\n",
    "                 'criterion':['gini','entropy'],\n",
    "                 'max_depth':[10,15,None]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pipeline for Random Forest:\n",
    "rf = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('rf', GridSearchCV(RandomForestClassifier(random_state=42),\n",
    "                                   param_grid=param_grid_rf,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1))\n",
    "              ],verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "**KNN (K Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The only parameter we are going to look at for the KNN model is `n_neighbors`, which indicates number of neighbors to use.  \n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# parameters to be tested for KNN\n",
    "param_grid_knn = {'n_neighbors':[3,5,10,15,20,50,100]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline for KNN:\n",
    "knn = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('knn', GridSearchCV(KNeighborsClassifier(weights='distance'),\n",
    "                                    param_grid=param_grid_knn,\n",
    "                                    cv=10,\n",
    "                                    n_jobs=-1))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "For our neural networks we are going to look at the methods used for our activation function. When discussing neural networks later on, we'll go into a bit more detail on what an activation function is and how these different methods work.  \n",
    "\n",
    "*Hyperparameter optimization:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# parameters to be tested for Neural Networks\n",
    "param_grid_nn = {'activation':['logistic','tanh','relu']}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "*Pipeline:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Create pipeline for Neural Networks:\n",
    "nn = Pipeline([('tfidf', TfidfVectorizer(tokenizer=StemAndTokenize())),\n",
    "               ('nn', GridSearchCV(MLPClassifier(batch_size=100,random_state=42,verbose=True,early_stopping=True),\n",
    "                                   param_grid=param_grid_nn,\n",
    "                                   cv=10,\n",
    "                                   n_jobs=-1))\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Before we can classify any new tweets we have to train a model using past tweets so the model can learn how to classify tweets into their respective classes. We will look into 6 classification models to train: `Logistic Regression`, `Naive Bayes`, `Support Vector Machine`, `Random Forest`, `K Nearest Neighbours` and `Neural Networks`.  \n",
    "\n",
    "_**NOTE:** After applying the gridsearch method above the following blocks of code will train longer than usual to find the optimal combination of hyperparameters. Patience is key._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                                           intercept_scaling=1,\n",
       "                                                           l1_ratio=None,\n",
       "                                                           max_iter=100,\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='l2',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='warn',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False),\n",
       "                              iid='warn', n_jobs=-1,\n",
       "                              param_grid={'C': [0.001, 0.01, 0.1, 1, 5, 10, 20,\n",
       "                                                50, 100],\n",
       "                                          'class_weight': [None, 'balanced']},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Logistic Regression model\n",
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 5, 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "best_param_lr = lr['lr'].best_params_\n",
    "print(best_param_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Naïve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                 tokenizer=<__main__.StemAndTokenize object at 0x0F55A510>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('nb',\n",
       "                 GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "                              estimator=MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True),\n",
       "                              iid='warn', n_jobs=-1,\n",
       "                              param_grid={'alpha': [0.001, 0.01, 0.1, 1, 5, 10,\n",
       "                                                    20, 50, 100]},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Naïve Bayes model\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "best_param_nb = nb['nb'].best_params_\n",
    "print(best_param_nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                            degree=3, gamma='auto_deprecated',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False, random_state=42,\n",
       "                                            shrinking=True, tol=0.001,\n",
       "                                            verbose=False),\n",
       "                              iid='warn', n_jobs=-1,\n",
       "                              param_grid={'C': [0.001, 0.01, 0.1, 1, 5, 10, 20,\n",
       "                                                50, 100],\n",
       "                                          'gamma': ['scale', 'auto'],\n",
       "                                          'kernel': ['linear', 'poly', 'rbf']},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=0))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the SVM model\n",
    "svm.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 100, 'gamma': 'scale', 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "best_param_svm = svm['svm'].best_params_\n",
    "print(best_param_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ............. (step 1 of 2) Processing tfidf, total=  10.9s\n",
      "[Pipeline] ............... (step 2 of 2) Processing rf, total=498.3min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words=None, strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='...\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=42,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False),\n",
       "                              iid='warn', n_jobs=-1,\n",
       "                              param_grid={'criterion': ['gini', 'entropy'],\n",
       "                                          'max_depth': [5, 10, 15],\n",
       "                                          'max_features': [0.5, 'log2', 'sqrt'],\n",
       "                                          'n_estimators': [20, 50, 75, 100, 250,\n",
       "                                                           500]},\n",
       "                              pre_dispatch='2*n_jobs', refit=True,\n",
       "                              return_train_score=False, scoring=None,\n",
       "                              verbose=0))],\n",
       "         verbose=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Random Forest model\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 15, 'max_features': 0.5, 'n_estimators': 75}\n"
     ]
    }
   ],
   "source": [
    "best_param_rf = rf['rf'].best_params_\n",
    "print(best_param_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**KNN (K Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                 tokenizer=<__main__.StemAndTokenize object at 0x119E3DF0>,\n",
       "                                 use_idf=True, vocabulary=None)),\n",
       "                ('knn',\n",
       "                 KNeighborsClassifier(algorithm='auto', leaf_size=30,\n",
       "                                      metric='minkowski', metric_params=None,\n",
       "                                      n_jobs=None, n_neighbors=5, p=2,\n",
       "                                      weights='uniform'))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the KNN model\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(knn['knn'].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:300: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['abov', 'afterward', 'alon', 'alreadi', 'alway', 'ani', 'anoth', 'anyon', 'anyth', 'anywher', 'becam', 'becaus', 'becom', 'befor', 'besid', 'cri', 'describ', 'dure', 'els', 'elsewher', 'empti', 'everi', 'everyon', 'everyth', 'everywher', 'fifti', 'forti', 'henc', 'hereaft', 'herebi', 'howev', 'hundr', 'inde', 'mani', 'meanwhil', 'moreov', 'nobodi', 'noon', 'noth', 'nowher', 'onc', 'onli', 'otherwis', 'ourselv', 'perhap', 'pleas', 'sever', 'sinc', 'sincer', 'sixti', 'someon', 'someth', 'sometim', 'somewher', 'themselv', 'thenc', 'thereaft', 'therebi', 'therefor', 'togeth', 'twelv', 'twenti', 'veri', 'whatev', 'whenc', 'whenev', 'wherea', 'whereaft', 'wherebi', 'wherev', 'whi', 'yourselv'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:568: UserWarning: Training interrupted by user.\n",
      "  warnings.warn(\"Training interrupted by user.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('tfidf',\n",
       "                 TfidfVectorizer(analyzer='word', binary=False,\n",
       "                                 decode_error='strict',\n",
       "                                 dtype=<class 'numpy.float64'>,\n",
       "                                 encoding='utf-8', input='content',\n",
       "                                 lowercase=True, max_df=1.0, max_features=None,\n",
       "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
       "                                 preprocessor=None, smooth_idf=True,\n",
       "                                 stop_words='english', strip_accents=None,\n",
       "                                 sublinear_tf=False,\n",
       "                                 token_patt...\n",
       "                               batch_size='auto', beta_1=0.9, beta_2=0.999,\n",
       "                               early_stopping=False, epsilon=1e-08,\n",
       "                               hidden_layer_sizes=(100,),\n",
       "                               learning_rate='constant',\n",
       "                               learning_rate_init=0.001, max_iter=200,\n",
       "                               momentum=0.9, n_iter_no_change=10,\n",
       "                               nesterovs_momentum=True, power_t=0.5,\n",
       "                               random_state=None, shuffle=True, solver='adam',\n",
       "                               tol=0.0001, validation_fraction=0.1,\n",
       "                               verbose=False, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the Neural Networks model\n",
    "nn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nn['nn'].best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Make predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The ultimate goal of training a classification model is to be able to classify new instances or new data. So next we make new classifications for new data(test dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the Logistic Regression model\n",
    "pred_lr = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Naïve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the Naïve Bayes model\n",
    "pred_nb = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the Linear SVM model\n",
    "pred_svm = svm.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the Random Forest model\n",
    "pred_rf = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**KNN (K Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the KNN model\n",
    "pred_knn = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Form a prediction set for the Neural Network model\n",
    "pred_nn = nn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Evaluate model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A [confusion matrix](https://towardsdatascience.com/understanding-confusion-matrix-a9ad42dcfd62) is performance metric used in a machine learning classification problem where the output can be two or more classes. It is a table with 4 different combinations of predicted and actual values. Each block in the table is a number of those classifications made "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The table consists of 4 measures that form part of the confusion matrix:\n",
    "      \n",
    "- **TP(True Positive)** : You predicted positive and it’s true. Number of correctly classified positives\n",
    "- **FP(False Positive)** : You predicted positive and it’s false. Number of incorrectly classified positives\n",
    "- **FN(Falso Negative)** : You predicted negative and it’s false. Number of incorrectly classified negatives\n",
    "- **TN(True Negative)** :  You predicted negative and it’s true. Number of correctly classified negatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "![confusionmatrix.png](confusionmatrix.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "labels = ['2: News', '1: Pro', '0: Neutral', '-1: Anti']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2: News</th>\n",
       "      <th>1: Pro</th>\n",
       "      <th>0: Neutral</th>\n",
       "      <th>-1: Anti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2: News</th>\n",
       "      <td>122</td>\n",
       "      <td>30</td>\n",
       "      <td>115</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1: Pro</th>\n",
       "      <td>18</td>\n",
       "      <td>179</td>\n",
       "      <td>201</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0: Neutral</th>\n",
       "      <td>26</td>\n",
       "      <td>97</td>\n",
       "      <td>1501</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1: Anti</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>131</td>\n",
       "      <td>557</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            2: News  1: Pro  0: Neutral  -1: Anti\n",
       "2: News         122      30         115        11\n",
       "1: Pro           18     179         201        27\n",
       "0: Neutral       26      97        1501       131\n",
       "-1: Anti          5      13         131       557"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_lr), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Naïve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_nb), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_svm), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_rf), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**KNN (K Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_knn), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "pd.DataFrame(data=confusion_matrix(y_test, pred_nn), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Classification report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "A [classification report](https://muthu.co/understanding-the-classification-report-in-sklearn/) measure the quality of the predictions made by a classification algorithm. it indicates how many predictions are True and how many are False. The report also uses the True Positives(TP), False Positives(FP), True Negatives(TN) and False Negatives(FN) to show the main classification metrics,i.e precision, recall and f1-score on a per-class basis.  These are the same concepts used in the confusion matrix above.\n",
    "\n",
    "**Precision** : The ability of a classifier to not label an instance positive when it is actually negative. So it considers how                  accurate a classifier is in predicting positive cases.\n",
    "                 For each class it is defined as the ratio of true positives to the sum of true and false positives:\n",
    "               \n",
    "                precision = TP/(TP + FP)\n",
    "               \n",
    "**Recall** : The ability of a classifier to find all positive instances. It considers the fraction of positives that were                     correctly identified.\n",
    "             For each class it is defined as the ratio of true positives to the sum of true positives and false negatives:\n",
    "              \n",
    "              recall = TP/(TP + FN)\n",
    "              \n",
    "**F1 Score** : A weighted harmonic mean of precision and recall such that the best score is 1.0 and the worst is 0.0. As a rule                 of thumb, the weighted average of F1 should be used to compare classifier models\n",
    "\n",
    "                F1 Score = 2*(Recall * Precision) / (Recall + Precision)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Classification Report from Logistic Regression Model \u001b[0m \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     2: News       0.75      0.44      0.55       278\n",
      "      1: Pro       0.60      0.44      0.51       425\n",
      "  0: Neutral       0.78      0.87      0.82      1755\n",
      "    -1: Anti       0.78      0.79      0.79       706\n",
      "\n",
      "    accuracy                           0.76      3164\n",
      "   macro avg       0.73      0.64      0.67      3164\n",
      "weighted avg       0.75      0.76      0.75      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Classification Report from Logistic Regression Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_lr, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Naïve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Classification Report from Naïve Model \u001b[0m \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     2: News       0.93      0.31      0.47       278\n",
      "      1: Pro       0.60      0.23      0.33       425\n",
      "  0: Neutral       0.71      0.92      0.80      1755\n",
      "    -1: Anti       0.80      0.72      0.75       706\n",
      "\n",
      "    accuracy                           0.73      3164\n",
      "   macro avg       0.76      0.54      0.59      3164\n",
      "weighted avg       0.73      0.73      0.70      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Classification Report from Naïve Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_nb, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**SVM (Support Vector Machine)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m Classification Report from SVM (Support Vector Machine) Model \u001b[0m \n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     2: News       0.80      0.44      0.57       278\n",
      "      1: Pro       0.68      0.44      0.53       425\n",
      "  0: Neutral       0.78      0.90      0.83      1755\n",
      "    -1: Anti       0.81      0.81      0.81       706\n",
      "\n",
      "    accuracy                           0.78      3164\n",
      "   macro avg       0.77      0.65      0.69      3164\n",
      "weighted avg       0.77      0.78      0.76      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Classification Report from SVM (Support Vector Machine) Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_svm, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report from Random Forest Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     2: News       0.70      0.27      0.39       278\n",
      "      1: Pro       0.52      0.38      0.44       425\n",
      "  0: Neutral       0.71      0.86      0.78      1755\n",
      "    -1: Anti       0.73      0.64      0.68       706\n",
      "\n",
      "    accuracy                           0.69      3164\n",
      "   macro avg       0.66      0.54      0.57      3164\n",
      "weighted avg       0.69      0.69      0.67      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Classification Report from Random Forest Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_rf, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**KNN (K Nearest Neighbors)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print('\\033[1m Classification Report from KNN(K Nearest Neighbours) Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_knn, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "**Neural Networks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report from Neural Networks Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     2: News       0.65      0.48      0.55       278\n",
      "      1: Pro       0.49      0.45      0.47       425\n",
      "  0: Neutral       0.78      0.82      0.80      1755\n",
      "    -1: Anti       0.76      0.77      0.76       706\n",
      "\n",
      "    accuracy                           0.73      3164\n",
      "   macro avg       0.67      0.63      0.65      3164\n",
      "weighted avg       0.72      0.73      0.72      3164\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('\\033[1m Classification Report from Neural Networks Model \\033[0m \\n')\n",
    "print(classification_report(y_test, pred_nn, target_names=['2: News', '1: Pro', '0: Neutral', '-1: Anti']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The `F1 score` is our main metric that we use to decide on the best model to use. Below is a dataframe that shows the models with their respective F1 scores from largest score i.e best model, to lowest score i.e poor model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "F1_dict = {'Model':['Logistic Regression','Naïve Bayes','Linear SVM','Random Forest','KNN','Neural Network'],\n",
    "        'F1_score' :[f1_score(y_test, pred_lr),\n",
    "       f1_score(y_test, pred_nb),\n",
    "       f1_score(y_test, pred_svm)\n",
    "       f1_score(y_test, pred_rf),\n",
    "       f1_score(y_test, pred_knn),\n",
    "       f1_score(y_test, pred_nn)]}\n",
    "# data = sorted(data.items(), key = lambda x: x[1], reverse = True) #sorting dictionary by values\n",
    "\n",
    "F1_score = pd.DataFrame(data=F1_dict, columns=['Model F1_score'])\n",
    "F1_score.sort_values(\"F1_score\", axis = 0, ascending = False, inplace = True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Saving important data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "with open('Logistic_regression.pkl','wb') as file:\n",
    "    pickle.dump(lr,file)\n",
    "    \n",
    "# Naïve Bayes\n",
    "with open('Naive_bayes.pkl','wb') as file:\n",
    "    pickle.dump(nb,file)\n",
    "    \n",
    "# SVM\n",
    "with open('SVM.pkl','wb') as file:\n",
    "    pickle.dump(svm,file)\n",
    "    \n",
    "# Random Forest\n",
    "with open('Random_forest.pkl','wb') as file:\n",
    "    pickle.dump(rf,file)\n",
    "    \n",
    "# KNN\n",
    "with open('KNN.pkl','wb') as file:\n",
    "    pickle.dump(knn,file)\n",
    "    \n",
    "# Neural Network\n",
    "with open('Neural_network.pkl','wb') as file:\n",
    "    pickle.dump(nn,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save the optimal parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic regression\n",
    "with open('best_param_dict_lr.pkl','wb') as file:\n",
    "    pickle.dump(best_param_lr,file)\n",
    "    \n",
    "# Naïve Bayes\n",
    "with open('best_param_dict_nb.pkl','wb') as file:\n",
    "    pickle.dump(best_param_nb,file)\n",
    "    \n",
    "# SVM\n",
    "with open('best_param_dict_svm.pkl','wb') as file:\n",
    "    pickle.dump(best_param_svm,file)\n",
    "    \n",
    "# Random Forest\n",
    "with open('best_param_dict_rf.pkl','wb') as file:\n",
    "    pickle.dump(best_param_rf,file)\n",
    "    \n",
    "# KNN\n",
    "with open('best_param_dict_knn.pkl','wb') as file:\n",
    "    pickle.dump(best_param_knn,file)\n",
    "    \n",
    "# Neural Network\n",
    "with open('best_param_dict_nn.pkl','wb') as file:\n",
    "    pickle.dump(best_param_nn,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "### Save the graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('Pie_chart.pkl','wb') as file:\n",
    "    pickle.dump(plot3,file)\n",
    "    \n",
    "with open('Common_words_pro.pkl','wb') as file:\n",
    "    pickle.dump(plot_wpro,file)\n",
    "    \n",
    "with open('Common_words_anti.pkl','wb') as file:\n",
    "    pickle.dump(plot_wanti,file)\n",
    "    \n",
    "with open('Common_words_neutral.pkl','wb') as file:\n",
    "    pickle.dump(plot_wneut,file)\n",
    "    \n",
    "with open('Common_words_news.pkl','wb') as file:\n",
    "    pickle.dump(plot_wnews,file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Produce output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = svm.predict(df_test['message']).reshape(-1, 1)\n",
    "Id = np.array(df_test.index).reshape(-1, 1)\n",
    "names = ['tweetid', 'sentiment']\n",
    "\n",
    "# Create output dataframe\n",
    "out = pd.DataFrame(np.append(Id,predictions, axis=1), columns=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Output to csv file\n",
    "out.to_csv('output.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Log parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "f1 = f1_score(y_test, pred_Lsvm, average='weighted')\n",
    "recall = recall_score(y_test, pred_Lsvm, average='weighted')\n",
    "precision = precision_score(y_test, pred_Lsvm, average='weighted')\n",
    "accuracy = accuracy_score(y_test, pred_Lsvm)\n",
    "confusion_mat = confusion_matrix(y_test, pred_Lsvm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#these will be logged to your sklearn-demos project on Comet.ml\n",
    "# (FINAL MODEL after gridsearch best parms)\n",
    "params={\"random_state\":42,\n",
    "        \"test_size\":0.2\n",
    "        \"model_type\":\"Linear SVM\"\n",
    "       }\n",
    "\n",
    "metrics = {\"f1\":f1,\n",
    "           \"recall\":recall,\n",
    "           \"precision\":precision,\n",
    "           \"accuracy\":accuracy\n",
    "            }\n",
    "\n",
    "# exp.log_dataset_hash(X_train_scaled)\n",
    "exp.log_parameters(params)\n",
    "exp.log_metrics(metrics)\n",
    "\n",
    "experiment.log_confusion_matrix(labels=['2: News', '1: Pro', '0: Neutral', '-1: Anti'],matrix=confusion_mat)\n",
    "\n",
    "experiment.log_figure(figure=plot1,figure_name='Distribution graph for different classes')\n",
    "experiment.log_figure(figure=plot2,figure_name='Number of types of comments')\n",
    "\n",
    "experiment.log_model(name='Linear SVM - base model', file_or_folder='pickled file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## End experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# experiment.end()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
